
page_title = 'Profile | Marcelo Peres'
page_icon = ':wave:'
name = 'Marcelo Peres'
role = 'Data Engineer & Analyst Professional'

info = '''\n
* - Git-lab-hub | CI/CD--Jenkins/Gitlab | Terraform
* - GCP--AWS | Storage | Athena/Redshift/Bigquery
* - ETL--ELT | Lambda/G functions/glue jobs/Datastage
* - Airflow | Sap | Oracle | API.
'''
email = 'brmarcelo.peres@gmail.com'
social_media = {
    'LinkedIn': 'https://www.linkedin.com/in/marcelo-peres-24611928/',
    'GitHub': 'https://github.com/Marcelo-Peres'
}

qualification = '## Experience & Qualifications'
qualification_info = '''
- ✔️ 8 Years of experience extracting actionable insights from data
- ✔️ Strong hands on experience and knowledge in Python, Excel and SQL
- ✔️ Good understanding of statistical principles and their respective applications
- ✔️ Excellent team-player and displaying strong sense of initiative on tasks
'''
skills = '## Hard Skills'
skills_info = '''
- 👩‍💻 Programming: Python (Pandas), SQL, Pyspark & Spark
- 📊 Data Visulization: PowerBi, Tableau, Plotly
- 📚 Modeling: Logistic regression, linear regression, decition trees
- 🗄️ Databases: Postgres, MySQL, SQL-Server & Oracle
'''
job_header = '## Work Experience'

job_t03 = '#### 🚧 Data Engineer | A3Data'
job_t03_time = '##### Dec 2022 - Mar 2023 | 04 months'
job_t03_info = '''<div style="text-align: justify;">
GCP - Google Cloud Platform\n
Stellantis - Datalake project

Responsible for creating tools to interect data at plataform.

- ► Tools used:
    * ✔️ Terraform;
    * ✔️ Google Storage;
    * ✔️ BigQuery;
    * ✔️ Google Functions;
    * ✔️ Airflow;
    * ✔️ Python;
    * ✔️ SQL.
'''

job_t02 = '#### 🚧 Data Engineer Consultant | Via Consulting'
job_t02_time = '##### Apr 2022 - Sep 2022 | 06 months'
job_t02_info = '''<div style="text-align: justify;">\n
###### Via Consulting - Project - Zendesk Replication
* ► Continuous pushing of data in a AWS environment using tools like:
    * ✔️ Pyspark Spark Glue jobs;
    * ✔️ Cloud Formation;
    * ✔️ AWS Athena;
    * ✔️ Apache Hudi metadata for data governance.

###### Unimed Insurance - Project - Stuffed Wallet (Carteira Recheada)

* ► Colaborating with the team in a ETL process using tools like:
    * ✔️ informatica Powercenter;
    * ✔️ PLSQL - Oracle.
The idea of the project is a campaign that supports the score of the company's brokers.

###### Smiles S.A. - Project - Gol Spend & Get

* ► AWS Python lambda function that validates a files to be called by an API.
    * << Resources >>:
    * ✔️ Cloud Formation;
    * ✔️ Python with unit tests;
    * ✔️ Github release info;
    * ✔️ Jenkins to observe github uploaded code;
    * ✔️ Sonar for code quality;
    * ✔️ End of Devops stack with deploy.
</div>'''

job_t01 = '#### 🚧 AWS & BI Consultant | BI4all'
job_t01_time = '##### Jul 2021 - May 2022 | 08 months'
job_t01_info = '''<div style="text-align: justify;">\n
###### Manserv Data Driven
* ► AWS Management asset
    * ✔️ Responsible for creating data pipelines to push data in S3 using python AWS lambda funtions.
    * ✔️ Using packages such as awswrangler, xmltodict, json and much more.
    * ✔️ Being involved in great projects with the relevant skills, accessing different APIs from several providers.
    * ✔️ Some of these ones are Volvo, Nuntec, Komatsu - Komtrax, Caterpillar and many others.
    * ✔️ Transforming XML and JSON API extrations into tabular data to be recorded in parquet table format, grating a better use of S3 bucket as much as gaing performance in a compressed file format.
</div>'''
